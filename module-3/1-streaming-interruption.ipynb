{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://docs.langchain.com/oss/python/langgraph/streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "\n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State)-> Literal [\"summarize_conversation\",END]:\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://docs.langchain.com/oss/python/langgraph/streaming#stream-graph-state) for graph state.\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk:  {'conversation': {'messages': AIMessage(content=\"Hi Faizan! It's great to meet you.\\n\\nHow can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='lc_run--3d450595-5863-46d8-ae2d-f65f64232970-0', usage_metadata={'input_tokens': 8, 'output_tokens': 391, 'total_tokens': 399, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 371}})}}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm Faizan\")]}, \n",
    "    config, stream_mode=\"updates\"\n",
    "    ):\n",
    "    print(\"chunk: \",  chunk)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Faizan! Nice to meet you again.\n",
      "\n",
      "What can I do for you today? How can I help?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"hi! I'm Faizan\")]}, \n",
    "    config, \n",
    "    stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Faizan\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Faizan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Faizan! It's great to meet you.\n",
      "\n",
      "How can I help you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Faizan\")\n",
    "\n",
    "for event in graph.stream(\n",
    "    {\"messages\": [input_message]}, \n",
    "    config, \n",
    "    stream_mode=\"values\"\n",
    "    ):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://docs.langchain.com/oss/python/langchain/models#advanced-streaming-topics:streaming-events), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatGoogleGenerativeAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Muhammad Ali Jinnah.\")\n",
    "async for event in graph.astream_events(\n",
    "    {\"messages\": [input_message]}, \n",
    "    config, \n",
    "    version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='**Muhammad Ali Jinnah** (born December 25, 1876, Karachi, British India – died September 11, 1948, Karachi, Pakistan) was a lawyer, politician, and the founder of Pakistan', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'input_tokens': 10, 'output_tokens': 1405, 'total_tokens': 1415, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 1354}})}\n",
      "{'chunk': AIMessageChunk(content=\". He is revered in Pakistan as **Quaid-e-Azam** (Great Leader) and **Baba-e-Qaum** (Father of the Nation).\\n\\nHere's a breakdown of his life and legacy:\\n\\n1.\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 50, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 50})}\n",
      "{'chunk': AIMessageChunk(content='  **Early Life and Education:**\\n    *   Born into a wealthy Gujarati merchant family in Karachi.\\n    *   Received his early education in Karachi and Bombay.\\n    *   At the age of 16, he moved', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 47, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 47})}\n",
      "{'chunk': AIMessageChunk(content=\" to London to study law at Lincoln's Inn, becoming the youngest Indian to be called to the bar.\\n    *   Upon returning to India in 1896, he established a successful legal practice in Bombay.\\n\\n2.  **\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 51, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 51})}\n",
      "{'chunk': AIMessageChunk(content='Early Political Career (Indian National Congress):**\\n    *   Jinnah began his political career in 1906, joining the Indian National Congress, which advocated for greater Indian self-government.\\n    *   He was initially', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content=' a strong proponent of Hindu-Muslim unity and was famously described by Sarojini Naidu as the \"Ambassador of Hindu-Muslim Unity.\"\\n    *   He played a key role in the 1916 Lucknow Pact, an', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 49, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 49})}\n",
      "{'chunk': AIMessageChunk(content=\" agreement between the Congress and the All-India Muslim League to present a united front to the British for constitutional reforms.\\n    *   However, he grew increasingly disillusioned with the Congress's methods, particularly Mahatma Gandhi's non-co\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content='operation movement, which Jinnah viewed as an appeal to mass emotion rather than constitutional politics. He resigned from the Congress in 1920.\\n\\n3.  **Leadership of the All-India Muslim League and the Pakistan Movement:**\\n    ', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content='*   Jinnah had joined the All-India Muslim League in 1913 but took on a more prominent leadership role in the 1930s.\\n    *   He became convinced that Muslims in British India constituted', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content=' a distinct nation and that their rights and identity would not be safe in a Hindu-majority independent India. This led to the formulation of the **Two-Nation Theory**.\\n    *   In 1940, at the Muslim', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content=\" League's annual session in Lahore, Jinnah presided over the adoption of the **Lahore Resolution**, which formally demanded the creation of independent states for Muslims in the northwestern and eastern parts of British India. This marked the formal beginning of the demand\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 49, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 49})}\n",
      "{'chunk': AIMessageChunk(content=' for Pakistan.\\n    *   He tirelessly campaigned and negotiated with the British and the Congress for the creation of a separate Muslim homeland.\\n\\n4.  **Partition and the Creation of Pakistan:**\\n    *   As World War II ended', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content=', the British government decided to grant independence to India. The negotiations were complex and often fraught with tension between Jinnah, Gandhi, and Jawaharlal Nehru.\\n    *   Ultimately, the British Viceroy Lord Mountbatten proposed the partition of India', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 48, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 48})}\n",
      "{'chunk': AIMessageChunk(content=\" into two independent states: India and Pakistan.\\n    *   Despite the immense challenges and the tragic violence and mass migrations that accompanied Partition, Jinnah's unwavering resolve led to the birth of Pakistan on August 14, 194\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 50, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 50})}\n",
      "{'chunk': AIMessageChunk(content='7.\\n\\n5.  **Governor-General of Pakistan:**\\n    *   Jinnah became the first Governor-General of Pakistan.\\n    *   His brief tenure (August 1947 – September 1948', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 49, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 49})}\n",
      "{'chunk': AIMessageChunk(content=') was marked by immense challenges: establishing a new government, managing the influx of millions of refugees, building a new administration, and dealing with the Kashmir conflict.\\n    *   He worked tirelessly to lay the foundations of the new nation, emphasizing', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 49, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 49})}\n",
      "{'chunk': AIMessageChunk(content=' principles of equality, justice, and religious freedom. In his famous speech on August 11, 1947, he stated: \"You are free; you are free to go to your temples, you are free to go to your mosques', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 51, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 51})}\n",
      "{'chunk': AIMessageChunk(content=' or to any other place of worship in this State of Pakistan. You may belong to any religion or caste or creed – that has nothing to do with the business of the State.\"\\n\\n6.  **Death and Legacy:**\\n    *   J', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 50, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 50})}\n",
      "{'chunk': AIMessageChunk(content=\"innah's health deteriorated rapidly after the creation of Pakistan, exacerbated by the immense stress and workload. He suffered from tuberculosis, a fact kept secret from the public.\\n    *   He passed away on September 11, 1948\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 51, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 51})}\n",
      "{'chunk': AIMessageChunk(content=\", just 13 months after Pakistan's independence.\\n    *   **Legacy:**\\n        *   He is revered in Pakistan as the architect of the nation, a visionary leader who secured a homeland for Muslims of the subcontinent.\\n        *\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 51, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 51})}\n",
      "{'chunk': AIMessageChunk(content='   His commitment to constitutionalism and his legal acumen are often highlighted.\\n        *   **Controversies:** Historians and political scientists continue to debate aspects of his legacy, including the necessity of Partition, his role in the accompanying violence, and the', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 50, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 50})}\n",
      "{'chunk': AIMessageChunk(content=' precise nature of the state he envisioned (secular vs. Islamic).\\n\\nMuhammad Ali Jinnah remains one of the most significant and transformative figures in 20th-century South Asian history, whose actions irrevocably shaped the geopolitical landscape of the region', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 50, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 50})}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', usage_metadata={'output_token_details': {'reasoning': 0}, 'output_tokens': 1, 'input_tokens': 0, 'input_token_details': {'cache_read': 0}, 'total_tokens': 1})}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--b5de3de2-072e-489c-ab88-8e7889312d78', chunk_position='last')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Muhammad Ali Jinnah.\")\n",
    "\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhammad Ali Jinnah (born December 25, 1876, Karachi, British India – died September 11, 1948, Karachi, Pakistan) was a pivotal figure in 20th-century South Asian history, universally recognized as the **founder of Pakistan**. He is revered in Pakistan as **Quaid-e-Azam** (Great Leader) and **Baba-e-Qaum** (Father of the Nation).\n",
      "\n",
      "Here's a summary of his life and impact:\n",
      "\n",
      "**1. Early Life and Education (1876-1906):**\n",
      "*   Born into a prosperous merchant family in Karachi.\n",
      "*   Demonstrated exceptional intellect from a young age.\n",
      "*   At 16, he moved to London to study law at Lincoln's Inn, becoming the youngest Indian to be called to the bar.\n",
      "*   Upon returning to India, he established a highly successful legal practice in Bombay, known for his sharp mind and persuasive arguments.\n",
      "\n",
      "**2. The \"Ambassador of Hindu-Muslim Unity\" (1906-1920s):**\n",
      "*   Jinnah began his political career with the **Indian National Congress** in 1906, advocating for greater Indian self-government.\n",
      "*   He was initially a strong proponent of Hindu-Muslim unity, believing in a united India where both communities could coexist and thrive. Sarojini Naidu famously called him the \"Ambassador of Hindu-Muslim Unity.\"\n",
      "*   He played a key role in the **Lucknow Pact of 1916**, an agreement between the Congress and the All-India Muslim League to present a united front for constitutional reforms.\n",
      "*   However, he grew increasingly disillusioned with the Congress's direction, particularly Mahatma Gandhi's non-cooperation movement, which Jinnah viewed as an appeal to mass emotion rather than constitutional politics. He resigned from the Congress in 1920.\n",
      "\n",
      "**3. The Shift Towards a Separate Homeland (1930s-1940):**\n",
      "*   While he had joined the **All-India Muslim League** in 1913, his leadership became central in the 1930s.\n",
      "*   Witnessing what he perceived as the marginalization of Muslim political interests and the rise of Hindu majoritarianism, Jinnah became convinced that Muslims in British India constituted a distinct nation. This led to the development of the **Two-Nation Theory**.\n",
      "*   In 1940, at the Muslim League's annual session in Lahore, Jinnah presided over the adoption of the **Lahore Resolution**, which formally demanded the creation of independent states for Muslims in the northwestern and eastern parts of British India. This was the formal articulation of the demand for Pakistan.\n",
      "\n",
      "**4. The Struggle for Pakistan (1940-1947):**\n",
      "*   Jinnah tirelessly campaigned and negotiated with the British and the Congress for the creation of a separate Muslim homeland.\n",
      "*   His unwavering resolve, legal acumen, and strategic political maneuvering were crucial in the complex and often fraught negotiations leading up to India's independence.\n",
      "*   Despite immense challenges, including widespread communal violence and mass migrations, Jinnah's leadership ultimately led to the **Partition of India** and the birth of Pakistan on **August 14, 1947**.\n",
      "\n",
      "**5. First Governor-General of Pakistan (1947-1948):**\n",
      "*   Jinnah became the first **Governor-General of Pakistan**.\n",
      "*   His brief 13-month tenure was marked by immense challenges: establishing a new government, managing the influx of millions of refugees, building a new administration from scratch, and dealing with the immediate crisis of the Kashmir conflict.\n",
      "*   He worked relentlessly to lay the foundations of the new nation, emphasizing principles of equality, justice, and religious freedom. In his famous August 11, 1947 speech, he declared: \"You are free; you are free to go to your temples, you are free to go to your mosques or to any other place of worship in this State of Pakistan. You may belong to any religion or caste or creed – that has nothing to do with the business of the State.\"\n",
      "\n",
      "**6. Death and Enduring Legacy:**\n",
      "*   Jinnah's health, already fragile, deteriorated rapidly under the immense stress of leading a new nation. He passed away on September 11, 1948, just over a year after Pakistan's independence.\n",
      "*   **Legacy:** He is revered in Pakistan as the architect of the nation, a visionary leader who secured a homeland for the Muslims of the subcontinent. His commitment to constitutionalism and his legal brilliance are often highlighted.\n",
      "*   **Controversies:** Historians and political scientists continue to debate aspects of his legacy, including the necessity of Partition, his role in the accompanying violence, and the precise nature of the state he envisioned (secular vs. Islamic).\n",
      "\n",
      "Muhammad Ali Jinnah remains one of the most significant and transformative figures in 20th-century South Asian history, whose actions irrevocably shaped the geopolitical landscape of the region."
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Muhammad Ali Jinnah.\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**⚠️ Notice**\n",
    "\n",
    "Since filming these videos, we've updated Studio so that it can now be run locally and accessed through your browser. This is the preferred way to run Studio instead of using the Desktop App shown in the video. It is now called _LangSmith Studio_ instead of _LangGraph Studio_. Detailed setup instructions are available in the \"Getting Setup\" guide at the start of the course. You can find a description of Studio [here](https://docs.langchain.com/langsmith/studio), and specific details for local deployment [here](https://docs.langchain.com/langsmith/quick-start-studio#local-development-server).  \n",
    "To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- 🚀 API: http://127.0.0.1:2024\n",
    "- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- 📚 API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the **Studio UI** URL shown above.\n",
    "\n",
    "The LangGraph API  [supports editing graph state](https://docs.langchain.com/langsmith/add-human-in-the-loop). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's [stream `values`](https://docs.langchain.com/oss/python/langgraph/streaming#stream-graph-state), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can  [use `messages` mode](https://docs.langchain.com/oss/python/langgraph/streaming#supported-stream-modes) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "<!--You can dig further into the types [~here~](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages) [here](https://docs.langchain.com/oss/python/langgraph/concepts/langgraph_server). -->\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata and response_metadata.get(\"finish_reason\"):\n",
    "                    print(f\"Response Metadata: Finish Reason - {response_metadata['finish_reason']}\")                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langsmith-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
